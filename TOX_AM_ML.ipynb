{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR5pscHIkQD1jJk8NV9a7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishola-github/InfernoRDN/blob/master/TOX_AM_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install RDKit (for Google Colab)\n",
        "!pip install rdkit-pypi\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "\n",
        "# Step 3: Example Single SMILES (Aspirin)\n",
        "smiles = \"CC(=O)Oc1ccccc1C(=O)O\"\n",
        "mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "if mol is not None:\n",
        "    # Generate ECFP4 fingerprints (2048 bits)\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)\n",
        "    print(f\"ECFP4 Fingerprint for {smiles} (first 50 bits): {list(fp.ToBitString())[:50]}\")\n",
        "\n",
        "    # Calculate common molecular descriptors\n",
        "    mw = Descriptors.MolWt(mol)\n",
        "    logp = Descriptors.MolLogP(mol)\n",
        "    h_donors = Descriptors.NumHDonors(mol)\n",
        "    h_acceptors = Descriptors.NumHAcceptors(mol)\n",
        "\n",
        "    print(f\"\\nMolecular Weight: {mw:.2f}\")\n",
        "    print(f\"LogP: {logp:.2f}\")\n",
        "    print(f\"Hydrogen Bond Donors: {h_donors}\")\n",
        "    print(f\"Hydrogen Bond Acceptors: {h_acceptors}\")\n",
        "else:\n",
        "    print(f\"Could not process SMILES: {smiles}\")\n",
        "\n",
        "# Step 4: Process a list of SMILES strings\n",
        "smiles_list = [\n",
        "    \"CC(=O)Oc1ccccc1C(=O)O\",  # Aspirin\n",
        "    \"CN1CCCC1C2=CN=CC=C2\",    # Nicotine\n",
        "    \"CC(=O)NC1=CC=C(C=C1)O\",  # Paracetamol\n",
        "    \"C1=CC=C2C(=C1)C=CC(=C2)O\" # Naphthol\n",
        "]\n",
        "\n",
        "# Initialize lists\n",
        "fingerprints = []\n",
        "molecular_weights = []\n",
        "\n",
        "# Generate features\n",
        "for s in smiles_list:\n",
        "    mol = Chem.MolFromSmiles(s)\n",
        "    if mol is not None:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n",
        "        fingerprints.append(fp)\n",
        "        molecular_weights.append(Descriptors.MolWt(mol))\n",
        "    else:\n",
        "        fingerprints.append(None)\n",
        "        molecular_weights.append(None)\n",
        "\n",
        "print(f\"\\nProcessed {len(smiles_list)} molecules.\")\n",
        "print(f\"Molecular Weights: {molecular_weights}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIDNMXicCttZ",
        "outputId": "fcdb7a11-1bf9-45ee-ed08-d4067ab15a85"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.3.0)\n",
            "ECFP4 Fingerprint for CC(=O)Oc1ccccc1C(=O)O (first 50 bits): ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
            "\n",
            "Molecular Weight: 180.16\n",
            "LogP: 1.31\n",
            "Hydrogen Bond Donors: 1\n",
            "Hydrogen Bond Acceptors: 3\n",
            "\n",
            "Processed 4 molecules.\n",
            "Molecular Weights: [180.15899999999996, 162.23600000000002, 151.165, 144.17299999999997]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Convert RDKit BitVect to numpy array\n",
        "fp_array = [np.array(fp) if fp is not None else np.zeros(1024) for fp in fingerprints]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(fp_array)\n",
        "df['MolWt'] = molecular_weights\n",
        "\n",
        "# Display\n",
        "print(\"\\nFeature matrix preview:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTH7nEb7C7Jr",
        "outputId": "3b407beb-a650-47a9-8e78-d9ae9dc1dd1d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature matrix preview:\n",
            "   0  1  2  3  4  5  6  7  8  9  ...  1015  1016  1017  1018  1019  1020  \\\n",
            "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     1     0     0     0   \n",
            "1  0  0  0  0  1  0  0  0  0  0  ...     0     0     0     0     1     0   \n",
            "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     1     0     0     0   \n",
            "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
            "\n",
            "   1021  1022  1023    MolWt  \n",
            "0     0     0     0  180.159  \n",
            "1     0     0     0  162.236  \n",
            "2     0     0     0  151.165  \n",
            "3     0     0     0  144.173  \n",
            "\n",
            "[4 rows x 1025 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-2, Import the required library\n",
        "import deepchem as dc\n",
        "import numpy as np\n",
        "from deepchem.models import MultitaskClassifier\n",
        "from deepchem.metrics import Metric\n",
        "from deepchem.feat import CircularFingerprint\n",
        "\n",
        "# Load dataset with ECFP fingerprints\n",
        "tox21_tasks, datasets, transformers = dc.molnet.load_tox21(\n",
        "    featurizer='ECFP', splitter='scaffold'\n",
        ")\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "# Define MultitaskClassifier using ECFP features\n",
        "model = MultitaskClassifier(\n",
        "    n_tasks=len(tox21_tasks),\n",
        "    n_features=train_dataset.X.shape[1],  # Use feature vector shape\n",
        "    layer_sizes=[1024, 512],  # two hidden layers\n",
        "    dropouts=[0.25, 0.25]\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "model.fit(train_dataset, nb_epoch=10)\n",
        "metric = Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "print(\"Valid scores:\", model.evaluate(valid_dataset, [metric], transformers))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cf0KgnnHreQ",
        "outputId": "d7657f35-b127-48f6-8b7e-c52eed89f7b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid scores: {'mean-roc_auc_score': np.float64(0.7079537341013312)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3, Define metrics\n",
        "from deepchem.metrics import Metric\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "metric = Metric(roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "# Evaluate model\n",
        "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
        "test_scores = model.evaluate(test_dataset, [metric], transformers)\n",
        "\n",
        "# Output results\n",
        "print(\"Train scores:\", train_scores)\n",
        "print(\"Validation scores:\", valid_scores)\n",
        "print(\"Test scores:\", test_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlK-GctzIqkR",
        "outputId": "350a2593-4c85-4cfe-ebcc-193fa35f4fe3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train scores: {'mean-roc_auc_score': np.float64(0.9416483907984454)}\n",
            "Validation scores: {'mean-roc_auc_score': np.float64(0.7079537341013312)}\n",
            "Test scores: {'mean-roc_auc_score': np.float64(0.6870289428490675)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-4, Install PyTorch in Google Colab (usually pre-installed or easily installed)\n",
        "# !pip install torch torchvision torchaudio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# --- Generate some synthetic data for demonstration ---\n",
        "num_compounds = 1000\n",
        "num_features = 200 # Represents molecular descriptors/fingerprints\n",
        "\n",
        "X = np.random.rand(num_compounds, num_features).astype(np.float32)\n",
        "y = np.random.randint(0, 2, num_compounds).astype(np.float32).reshape(-1, 1) # Ensure y is 2D\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets and DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the Neural Network model\n",
        "class ToxicityPredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ToxicityPredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(128, 1) # Output layer for binary classification\n",
        "        self.sigmoid = nn.Sigmoid() # Sigmoid for binary classification output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout1(self.relu1(self.fc1(x)))\n",
        "        x = self.dropout2(self.relu2(self.fc2(x)))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = ToxicityPredictor(num_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss() # Binary Cross-Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "print(\"Training the PyTorch model...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set model to training mode\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad() # Zero the gradients\n",
        "        outputs = model(inputs) # Forward pass\n",
        "        loss = criterion(outputs, labels) # Calculate loss\n",
        "        loss.backward() # Backward pass\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "    print(f\"Epoch, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval() # Set model to evaluation mode\n",
        "with torch.no_grad(): # Disable gradient calculation during evaluation\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).float() # Convert probabilities to binary\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Make sample predictions\n",
        "    sample_inputs = X_test_tensor\n",
        "    sample_outputs = model(sample_inputs)\n",
        "    sample_predictions_prob = sample_outputs.flatten().numpy()\n",
        "    sample_predictions_binary = (sample_outputs > 0.5).int().flatten().numpy()\n",
        "\n",
        "    print(f\"\\nSample inputs (first 5 features): {sample_inputs.numpy()}\")\n",
        "    print(f\"Sample predictions (probabilities): {sample_predictions_prob}\")\n",
        "    print(f\"Sample predictions (binary): {sample_predictions_binary}\")\n",
        "    print(f\"True labels for sample: {y_test_tensor.flatten().numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dADRgYCFB579",
        "outputId": "143dee1c-291f-472d-9d26-76a8858b0283"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the PyTorch model...\n",
            "Epoch, Loss: 0.6851\n",
            "Epoch, Loss: 0.6317\n",
            "Epoch, Loss: 0.5432\n",
            "Epoch, Loss: 0.3144\n",
            "Epoch, Loss: 0.3096\n",
            "Epoch, Loss: 0.0934\n",
            "Epoch, Loss: 0.1432\n",
            "Epoch, Loss: 0.0608\n",
            "Epoch, Loss: 0.0219\n",
            "Epoch, Loss: 0.0343\n",
            "Epoch, Loss: 0.1004\n",
            "Epoch, Loss: 0.0452\n",
            "Epoch, Loss: 0.0544\n",
            "Epoch, Loss: 0.0059\n",
            "Epoch, Loss: 0.0125\n",
            "Epoch, Loss: 0.0108\n",
            "Epoch, Loss: 0.0026\n",
            "Epoch, Loss: 0.0042\n",
            "Epoch, Loss: 0.0062\n",
            "Epoch, Loss: 0.0336\n",
            "\n",
            "Test Accuracy: 0.5150\n",
            "\n",
            "Sample inputs (first 5 features): [[-0.7930219  -0.5234613  -0.05251822 ... -0.38024768 -0.14027023\n",
            "  -1.0376816 ]\n",
            " [ 0.8457245  -0.37734002  0.0726507  ... -1.7467203   1.4429984\n",
            "   1.6335025 ]\n",
            " [-0.9890757   0.7904778  -1.2014533  ... -0.39247754 -0.15060821\n",
            "   1.0188866 ]\n",
            " ...\n",
            " [ 0.55854815 -1.2704556  -1.695796   ... -0.84608126 -1.2264547\n",
            "  -0.98187596]\n",
            " [-1.8054985  -0.6797335   1.2470664  ... -0.19528732  0.4276243\n",
            "  -1.4055729 ]\n",
            " [ 1.6152296   1.5446903   1.5264565  ...  1.3151361  -0.915636\n",
            "  -1.3208405 ]]\n",
            "Sample predictions (probabilities): [9.9674892e-01 3.1012747e-02 7.0461684e-01 2.8449419e-01 2.1834581e-03\n",
            " 3.9018912e-04 9.9877304e-01 4.1755945e-03 1.0699947e-01 1.1538165e-01\n",
            " 9.3423289e-01 9.9220467e-01 1.2824472e-04 6.9139865e-03 7.8071493e-01\n",
            " 2.0270988e-03 6.7696194e-03 9.9064434e-01 9.9339408e-01 9.6498466e-01\n",
            " 4.9455673e-01 5.5826634e-01 9.9998975e-01 1.9365971e-01 9.9708384e-01\n",
            " 3.1896028e-01 9.8578727e-01 1.5398683e-03 9.9814796e-01 9.3468237e-01\n",
            " 8.4301416e-04 9.9905807e-01 9.7289050e-01 1.7515185e-01 5.2268007e-03\n",
            " 9.5809594e-04 3.0609983e-01 9.0985072e-01 5.7000691e-01 1.0540697e-03\n",
            " 2.2789162e-02 9.9962795e-01 9.5787221e-01 2.4646106e-01 2.8766392e-04\n",
            " 6.5294075e-01 9.9995518e-01 2.0000798e-05 9.2379946e-01 1.7897179e-03\n",
            " 9.9969459e-01 9.9969184e-01 9.9337441e-01 2.9137170e-01 4.0148667e-01\n",
            " 9.4113284e-01 4.0267602e-02 1.4566812e-04 5.6811641e-03 4.2345877e-05\n",
            " 7.8787327e-02 2.9571882e-02 3.7410419e-04 4.0887734e-01 1.2498808e-03\n",
            " 9.9932206e-01 9.9500567e-01 9.9885499e-01 5.9509420e-01 9.0669608e-03\n",
            " 9.4566685e-01 9.7160202e-01 5.3566284e-02 9.5471370e-01 7.9520261e-01\n",
            " 9.9815828e-01 9.9054152e-01 6.6538200e-02 1.6124762e-03 7.4557072e-01\n",
            " 4.3803003e-01 9.8661429e-01 8.5417094e-05 8.9729923e-01 5.8569476e-02\n",
            " 9.8896420e-01 1.1403362e-04 8.2590079e-01 9.9906522e-01 1.5369909e-02\n",
            " 9.9997437e-01 9.9764144e-01 7.8969501e-02 6.2142447e-02 1.2269557e-01\n",
            " 3.0971941e-01 9.9729472e-01 9.9861205e-01 9.9973971e-01 1.0837341e-02\n",
            " 2.4011424e-01 7.2750086e-01 6.5073866e-04 4.2437967e-02 9.8410589e-01\n",
            " 1.5172412e-04 8.1769168e-01 1.0660670e-02 2.2939681e-01 1.1084546e-02\n",
            " 5.4368171e-05 1.7367581e-02 7.1900830e-02 1.7307873e-06 1.9617893e-03\n",
            " 9.9998260e-01 6.0306591e-01 9.2480272e-01 9.9789608e-01 9.8587763e-01\n",
            " 9.9182749e-01 6.1689015e-04 9.4095087e-01 9.9498910e-01 3.5314549e-02\n",
            " 1.3244417e-02 9.9958509e-01 9.5885628e-01 2.0548657e-03 9.3681514e-01\n",
            " 9.9520183e-01 9.9953377e-01 3.5581918e-04 1.7526297e-01 4.6011886e-01\n",
            " 9.6054417e-01 6.3804018e-01 9.7747642e-01 3.2989781e-05 6.9511563e-01\n",
            " 6.8958545e-01 4.2761165e-01 9.9592966e-01 3.6516961e-02 5.0707817e-01\n",
            " 2.2272069e-03 2.1256140e-04 9.9991286e-01 5.2017748e-01 6.8723230e-04\n",
            " 9.2955954e-05 9.9106887e-03 1.5685324e-02 9.9950325e-01 9.9917090e-01\n",
            " 5.7469666e-01 9.4748330e-01 7.8145451e-05 1.6669188e-01 9.9941921e-01\n",
            " 9.9952149e-01 9.9235994e-01 9.5618969e-01 8.8696003e-01 5.6110541e-05\n",
            " 8.2678771e-01 5.4827142e-01 9.9709952e-01 9.9646568e-01 9.9994409e-01\n",
            " 9.9852556e-01 2.8882334e-02 9.9992669e-01 9.9067467e-01 9.7165287e-02\n",
            " 9.9999058e-01 9.9593276e-01 1.1556748e-04 8.6977655e-01 1.9435644e-02\n",
            " 1.0097929e-01 9.9958020e-01 9.9982685e-01 3.7436086e-01 7.3457807e-01\n",
            " 1.0839483e-05 1.0560537e-01 9.7678214e-01 9.9853802e-01 9.3126357e-01\n",
            " 6.7487851e-02 9.9757785e-01 9.9897778e-01 2.4419542e-01 9.9841309e-01\n",
            " 8.6864501e-01 2.7145147e-01 9.9854761e-01 4.8963416e-01 8.8880129e-02]\n",
            "Sample predictions (binary): [1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 0 0\n",
            " 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
            " 0 0 1 1 1 0 1 1 0 1 1 0 1 0 0]\n",
            "True labels for sample: [1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    }
  ]
}